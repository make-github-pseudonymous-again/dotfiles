#!/usr/bin/env python3

import sys

args = sys.argv[1:]

log = lambda *x, **y: print(*x, **y, file=sys.stderr)

if not args :
    log( 'usage: bib.get <query>')
    sys.exit( 1 )

import json
from datetime import datetime
import urllib.request

import lxml.html as html
import lxml.etree as etree
from lxml.cssselect import CSSSelector

sel = lambda h, s: CSSSelector(s)(h)

REQUEST = 'https://dblp.uni-trier.de/search?{}'

query = args[0]

def now ( ) :
    return datetime.now().astimezone().isoformat(timespec='seconds')

def dblp_query ( query ) :

    data = { 'q' : query }
    url_values = urllib.parse.urlencode( data )
    url = REQUEST.format(url_values)

    log(url)

    output = {
        'time' : { } ,
        'query' : query ,
        'url' : url
    }

    try:

        output['time']['send'] = now()
        tree = html.parse(urllib.request.urlopen(url))
        output['time']['receive'] = now()

    except urllib.error.HTTPError:
        output['time']['receive'] = now()
        log('failed to download', url)
        output['returncode'] = 2
        output['error'] = { 'message' : 'failed to download url' }
        return output

    # authors

    AUTHORS_SELECTOR = '#completesearch-authors a[itemprop="url"]'
    entries = sel( tree , AUTHORS_SELECTOR )

    authors = []

    for entry in entries :

        url = entry.get('href')

        # do at the end
        etree.strip_tags(entry,'*')
        name = entry.text

        x = {
            'url' : url ,
            'name' : name ,
        }

        authors.append(x)

    # venues

    VENUES_SELECTOR = '#completesearch-venues > div.body ul li a'
    entries = sel( tree , VENUES_SELECTOR )

    venues = []

    for entry in entries :

        url = entry.get('href')

        # do at the end
        etree.strip_tags(entry,'*')
        name = entry.text

        x = {
            'url' : url ,
            'name' : name ,
        }

        venues.append(x)

    # publications

    PUBLICATIONS_SELECTOR = '.publ-list > .entry'
    entries = sel( tree , PUBLICATIONS_SELECTOR )

    publications = []

    for entry in entries :

        id = entry.get('id')

        publication_authors = []

        for author_entry in sel( entry , '.data > span[itemprop="author"] > a' ) :

            url = author_entry.get('href')

            # do at the end
            etree.strip_tags(author_entry,'*')
            name = author_entry.text

            author = {
                'url' : url ,
                'name' : name
            }


            publication_authors.append( author )

        metadata = { }

        for ispartof_entry in sel( entry , '.data span[itemprop="isPartOf"]' ) :

            key = ispartof_entry.get('itemtype')

            # do at the end
            etree.strip_tags(ispartof_entry,'*')
            value = ispartof_entry.text

            metadata[key] = value

        title = sel( entry , 'span.title' )[0].text
        date = sel( entry , 'span[itemprop="datePublished"]' )[0].text

        x = {
            'id' : id ,
            'title' : title ,
            'date' : date ,
            'bibtex' : {
                'condensed' : 'https://dblp.uni-trier.de/rec/bib0/{}.bib'.format(id) ,
                'standard' : 'https://dblp.uni-trier.de/rec/bib1/{}.bib'.format(id) ,
                'crossref' : 'https://dblp.uni-trier.de/rec/bib2/{}.bib'.format(id) ,
            } ,
            'xml' : 'https://dblp.uni-trier.de/rec/xml/{}.xml'.format(id),
            'rdf' : 'https://dblp.uni-trier.de/rec/rdf/{}.rdf'.format(id),
            'authors' : publication_authors ,
            'metadata' : metadata ,
        }

        publications.append(x)

    output['results'] = {
        'authors' : authors ,
        'venues' : venues ,
        'publications' : publications ,
    }
    output['returncode'] = 0
    return output

data = dblp_query( query )
json.dump( data , sys.stdout )
sys.exit( data['returncode'] )
