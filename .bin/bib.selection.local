#!/usr/bin/env python3
# vi:syntax=python

import arrow
from collections import defaultdict

# prompt = ['dmenu_center', '--rest', '-i', '-t', '-p', 'bib', '-sb', '#8080ff', '-l', '10']
prompt = ['fzf-menu', '--lines', '10', '-m', '--prompt', 'bib > ']
querystring = 'ext:bib'
sortby = 'mtime'
ascending = False

def formatentry(entry):

    items = [
        'ENTRYTYPE' ,
        'ID' ,
        'author' ,
        'title' ,
        'year' ,
        'month' ,
        'journal' ,
        'booktitle' ,
        'volume' ,
        'publisher' ,
        'keyword' ,
        'pages' ,
        'abstract' ,
        'comments' ,
    ]

    formatarray = map(lambda x: '{'+x+'}', filter(entry.__contains__ , items))

    # paths = ':'.join(citations[frozenset(entry.items())])

    return ' -- '.join(formatarray).format(**entry)

import os
import sys
import logging
# recoll
from recoll import recoll, rclextract
# bibtex
import bibtexparser
from bibtexparser.bwriter import BibTexWriter
from bibtexparser.bibdatabase import BibDatabase
# dmenu
from subprocess import check_output

log = logging.getLogger(__name__)
log.setLevel(logging.INFO)

handler = logging.StreamHandler(sys.stdout)
handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
log.addHandler(handler)

# read all local bib files (surprisingly fast)

db = recoll.connect()

query = db.query()

if sortby:
    query.sortby(sortby, ascending=ascending)

n = query.execute(querystring)

log.info('{} results'.format(n))

docs = list(query)

db = BibDatabase()
entries = [ ]
citations = defaultdict(list)

for doc in docs:

    log.info('parsing %s', doc.url)

    if doc.ipath:
        extractor = rclextract.Extractor(doc)
        path = extractor.idoctofile(doc.ipath, doc.mimetype).decode()

    else:
        path = doc.url[7:]

    try:
        with open(path) as bibtex_file:
            bibtex_str = bibtex_file.read()
    except FileNotFoundError as e:
        log.error(e)
        continue

    bib_database = bibtexparser.loads(bibtex_str)
    # should probably just count here
    entries += bib_database.entries

    for entry in bib_database.entries:
        # normalize values
        for key, value in entry.items():
            entry[key] = value.replace('\n', ' ').replace('\r', '')
        # remove duplicates and keep pointer to origin
        citations[frozenset(entry.items())].append(path)

    if doc.ipath and path[:5] == '/tmp/':
        log.info('deleting {}'.format(path))
        # just in case someone screws up upstreams
        os.remove(path)

log.info('Found {} entries'.format(len(entries)))

entries = list(map(dict,citations))

log.info('From which {} are unique'.format(len(entries)))

# prompt with dmenu

def genline(i, entry, formatentry=formatentry):
    return formatentry(entry) + ' ' + str(i)

inputlines = sorted(genline(i, entry) for i, entry in enumerate(entries))

raw = '\n'.join(inputlines).encode()

try:
    # TODO can stream input to fzf
    result = check_output(prompt, input=raw)

except Exception as e:
    log.exception('dmenu/fzf failed')
    sys.exit(1)

# decode dmenu output

outputlines = result.decode().splitlines()

out = BibDatabase()

where = []

for line in outputlines:

    try:

        i = int(line.split()[-1])

    except Exception as e:
        log.exception('could not parse line number')
        sys.exit(2)

    try:
        entry = entries[i]
    except IndexError as e:
        log.exception('index not in range')
        sys.exit(3)

    if genline(i, entry) != line:
        log.error('lines do not match')
        sys.exit(4)

    out.entries.append(entry)

    where += citations[frozenset(entry.items())]

# copy to clipboard

writer = BibTexWriter()

entry_text = writer.write(out)

print(*where, sep='\n')
print(entry_text, end='')

raw = entry_text.encode()

check_output(['xsel', '-b'], input=raw)
